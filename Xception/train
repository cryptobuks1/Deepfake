
from data import deepfakedata
from xception import SeparableConv2d ,Block , xception 
import time
import torch
from torchvision import datasets, models, transforms
import os
import torch.nn as nn

import torch.optim as optim
import torchvision
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader ,Dataset , random_split

import numpy as np
import joblib
from efficientnet_pytorch import EfficientNet
from PIL import Image

augmentation = torchvision.transforms.Compose([torchvision.transforms.Resize(200),
                                                    torchvision.transforms.RandomCrop(200),                                                                            
                                                    torchvision.transforms.RandomHorizontalFlip(),
                                                    torchvision.transforms.ToTensor(),
                                                    torchvision.transforms.Normalize([0.485, 0.456, -.406],[0.229, 0.224, 0.225])
                                                    ])

def train_model(loader, model , criterion , optimizer ,scheduler , num_epochs):
    
    since = time.time()
    
    best_acc = 0.0 
    
    model.train()
    for epoch in range(num_epochs):
       print('Epoch : {}/{}'.format(epoch, num_epochs - 1))
       print('-' * 10)
       accuracy = 0.0
       running_loss = 0.0
       for i ,data in enumerate(loader , 0):
           inputs , labels =data['image'] , data['label']
           
           inputs, labels = inputs.to(device , dtype=torch.float32), labels.to(device)
           optimizer.zero_grad()          
           outputs = model(inputs)
           
           loss = criterion(outputs, labels)
           
           
           loss.backward()
           optimizer.step()
           
           _, pred = torch.max(torch.sigmoid(outputs), 1)
           acc = torch.sum(pred==labels).item()
           accuracy += acc

           running_loss += loss.item()
   
       print("Train Loss: {}".format(running_loss / face.__len__()))
       print("Train Accuracy: {}".format(accuracy / face.__len__()))
       
       
    torch.save(model.state_dict() , 'flozen.pth')
    return model
    
def test(loader, model):
    model.eval()
    accuracy = 0.
    with torch.no_grad():
        for i,data in enumerate(loader , 0):
            
            inputs , labels =data['image'] , data['label']
            inputs, labels = inputs.to(device , dtype=torch.float32), labels.to(device)
            ou = model(inputs)
            _, pred = torch.max(torch.sigmoid(ou), 1)
            
            # print()
            # print(pred)
            # print(labels)
            # print()
            accuracy += torch.sum(pred==labels).item()
        
    print("Test Accuracy: {}".format(accuracy / len(face)))

class testdata(Dataset):
    def __init__(self ,Dir ,label ,transforms):
        self.dir = Dir
        self.label = label
        self.transforms = transforms
           
    def __len__(self):   #抓幾張圖片

        return 50   # idx 從 0 開始算
    
    def __getitem__(self  , idx ):   # 弄好 (img , label)
        
        if os.path.exists(self.dir+'/'+str(idx+1)+'.jpg'):
            pic = Image.open(self.dir+'/'+str(idx+1)+'.jpg').convert('RGB')
            if self.transforms is not None:
                pic = self.transforms(pic)
        
            sample = {'image': pic , 'label': self.label}  
            return sample
        else:
            print('file not found')
            print(self.dir+'/'+str(idx+1)+'.jpg')
            return 0
              
        
if __name__ =="__main__":

    
    #model = EfficientNet.from_pretrained('efficientnet-b0' , num_classes=2)
    #model = xception()
    
    
    criterion = nn.CrossEntropyLoss()
    
    optimizer_ft = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)
    
    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)
    
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    
      
    
# test dataset ===========================================================================
    path = 'D:/Celeb-DF-v2/test'
    l = []
    face = testdata('D:/Celeb-DF-v2/test/id29_id38_0008' , 1 , transforms = augmentation)
    c = 0
    for i in os.listdir(path):
        print(path+'/'+i)
        if(len(i)>10):
            face += testdata(path+'/'+i , 1 , transforms = augmentation)
        else:
            face += testdata(path+'/'+i , 0 , transforms = augmentation)
        c+=1
        if(c==517):
            break
   
    
# train dataset ===========================================================================

    face = deepfakedata(6, 'D:/Celeb-DF-v2/train/real' , 'D:/Celeb-DF-v2/train/fake',transforms = augmentation ) 
    
    
    for i in range(1,51):
        face += deepfakedata(i, 'D:/Celeb-DF-v2/train/real' , 'D:/Celeb-DF-v2/train/fake',transforms = augmentation )
    

    train_loader = DataLoader( face , batch_size = 10 , shuffle = True , num_workers = 0 )

    
# training ================================================================================ 

    #model = train_model(train_loader, model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100 )    
    
    
# test =============================================================================
    
    a = torch.load('flozen.pth', map_location='cpu')
    model.load_state_dict(a)
    
    test(train_loader , model)
    
